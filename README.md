# Rakuten MLOps Project

Ce projet est une base complÃ¨te pour mettre en place un pipeline MLOps moderne appliquÃ© Ã  une tÃ¢che de classification de produits e-commerce. Il inclut l'entraÃ®nement de modÃ¨les, la prÃ©diction, la surveillance des dÃ©rives de donnÃ©es, l'orchestration et l'exposition via une API.

---

## ğŸ”§ Installation rapide (en local)

```bash
conda create -n Rakuten-project python=3.9
conda activate Rakuten-project
pip install -r requirements.txt
```

---

## ğŸ³ Lancer toute la stack avec Docker

```bash
docker-compose up --build
```

ou pour lancer un composant spÃ©cifique :

```bash
docker-compose run --rm monitor
docker-compose run --rm api-fast
```

---

## âš™ï¸ Commandes Makefile disponibles

```bash
make train             # EntraÃ®nement depuis Dockerfile.dev
make predict           # Lancement de la prÃ©diction (via conteneur api-fast)
make monitor           # GÃ©nÃ¨re les rapports de dÃ©rive
make api               # Lance l'API en standalone
make dashboard         # Affiche le dashboard CLI de monitoring
make full-run          # EntraÃ®nement + prÃ©diction + monitoring + dashboard
make full-run-api      # full-run + lancement de l'API
make no-train-run      # PrÃ©diction + monitoring + dashboard (sans entraÃ®nement)
make up / make down    # DÃ©marrer / arrÃªter tous les conteneurs
make lint / format     # QualitÃ© de code
```

---

## ğŸ§± Structure du projet

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  <- DonnÃ©es brutes (images + fichiers .csv)
â”‚   â”œâ”€â”€ preprocessed/         <- DonnÃ©es transformÃ©es pour les modÃ¨les
â”‚   â”œâ”€â”€ current.csv / reference.csv <- Pour le monitoring de dÃ©rive
â”‚
â”œâ”€â”€ models/                   <- ModÃ¨les entraÃ®nÃ©s (Pickle, JSON, etc.)
â”œâ”€â”€ logs/                     <- Logs d'entraÃ®nement et logs API
â”œâ”€â”€ notebooks/                <- Analyses exploratoires et prototypes
â”œâ”€â”€ monitoring/               <- Evidently : dÃ©rive des donnÃ©es
â”‚   â”œâ”€â”€ monitor.py
â”‚   â””â”€â”€ reports/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py               <- EntraÃ®nement
â”‚   â”œâ”€â”€ predict.py            <- PrÃ©diction
â”‚   â”œâ”€â”€ data/                 <- Scripts d'import/preprocessing
â”‚   â”œâ”€â”€ features/             <- Feature engineering
â”‚   â”œâ”€â”€ models/               <- Architecture LSTM + VGG16
â”‚   â””â”€â”€ config/               <- ParamÃ¨tres
â”‚
â”œâ”€â”€ tests/                    <- Tests unitaires
â”œâ”€â”€ Dockerfile*               <- Dockerisation des services
â”œâ”€â”€ docker-compose.yml        <- Orchestration multi-container
â”œâ”€â”€ requirements.txt          <- DÃ©pendances Python
â”œâ”€â”€ Makefile                  <- Automatisation des tÃ¢ches
â””â”€â”€ README.md                 <- Tu y es !
```

---

## ğŸ“Š Architecture du projet (Mermaid)

```mermaid
graph TD
  A[User Input] -->|Text + Image| API[FastAPI]
  API -->|PrÃ©traitement| Preproc[Text & Image Preprocessor]
  Preproc -->|Vecteurs| Models[LSTM + VGG16]
  Models -->|Fusion| Combiner[Poids optimaux]
  Combiner -->|RÃ©sultat| Pred[Prediction JSON]
  Pred -->|MLflow Log| MLflow[(Tracking Server)]

  subgraph Docker Containers
    API
    Models
    MLflow
    Monitor[Evidently]
  end
```

---

## ğŸš€ Ã‰tapes principales (manuelles)

```bash
# 1. Import des donnÃ©es
python src/data/import_raw_data.py

# 2. PrÃ©paration du dataset
python src/data/make_dataset.py data/raw data/preprocessed

# 3. EntraÃ®nement
python src/main.py

# 4. PrÃ©diction
python src/predict.py --dataset_path "data/preprocessed/X_test_update.csv" --images_path "data/preprocessed/image_test"

# 5. Monitoring avec Evidently
docker-compose run --rm monitor
```

Les prÃ©dictions sont sauvegardÃ©es dans `data/preprocessed/predictions.json`.

---

## ğŸŒ API dâ€™infÃ©rence (FastAPI)

Lâ€™API permet de soumettre des donnÃ©es (JSON) pour obtenir des prÃ©dictions :

```bash
docker-compose run --rm api-fast
```

- Endpoint : `POST /predict`
- Format attendu :
```json
{
  "description": "Chaussures en cuir pour homme",
  "image": "<base64 ou chemin local>"
}
```

- RÃ©ponse :
```json
{
  "predicted_category": "263",
  "category_id": 263,
  "confidence": 0.87
}
```

Accessible sur [http://localhost:8000](http://localhost:8000)

---

## ğŸ“Š Monitoring avec Evidently

Deux rapports sont gÃ©nÃ©rÃ©s automatiquement :

- `monitoring/reports/drift_report.html`
- `monitoring/reports/drift_report.json`

Ces fichiers comparent `reference.csv` (ancien jeu) et `current.csv` (nouveau jeu) pour dÃ©tecter toute dÃ©rive de donnÃ©es.

---

## ğŸ›°ï¸ Orchestration (Flyte)

Flyte est utilisÃ© pour orchestrer les Ã©tapes du pipeline ML :

```bash
flytectl demo start          # Lancement du cluster Flyte en local
pyflyte run workflows/pipeline.py my_workflow
```

> Flyte offre une exÃ©cution distribuÃ©e, un tracking natif et une meilleure rÃ©silience que Airflow pour les projets MLOps.

---

## ğŸ“ˆ Suivi des expÃ©riences avec MLflow

Le serveur MLflow est dÃ©jÃ  intÃ©grÃ© via Docker et enregistre automatiquement :

- Les hyperparamÃ¨tres
- Les performances (accuracy, loss, etc.)
- Les modÃ¨les (`.pth`)
- Les mÃ©triques de lâ€™API (via endpoint `/predict`)

Accessible sur : [http://localhost:5001](http://localhost:5001)

---

## ğŸ§ª Tests

Lancer les tests unitaires :

```bash
make test
```

---

## ğŸ“š Ressources utiles

- [Evidently](https://github.com/evidentlyai/evidently)
- [Flyte](https://docs.flyte.org/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [MLflow](https://mlflow.org/)
- [cookiecutter-data-science](https://drivendata.github.io/cookiecutter-data-science/)

---

<p><small>Projet inspirÃ© du template <a href="https://drivendata.github.io/cookiecutter-data-science/" target="_blank">cookiecutter data science</a></small></p>
